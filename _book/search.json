[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fake_Instagram",
    "section": "",
    "text": "1 Detección de cuentas “Fake” de Instagram\nDetectar cuentas no reales o “fake” en Instagram no es un trabajo fácil. Sin embargo, es posible construir un modelo que te diga la probabilidad de que una cuenta de Instagram sea real o no.\nPara este propósito, nos basaremos en un conjunto de datos que recopila una variedad de características que podrían servir como indicadores de la falsedad de una cuenta.\nMediante el análisis exploratorio de estos datos, nuestro objetivo es identificar patrones y tendencias que permitan diferenciar de manera efectiva entre cuentas auténticas y falsas en la plataforma.\nTambién aplicaremos otras técnicas para un análisis más avanzado de nuestros datos, como son la reglas de asociación y análisis de conceptos formales, entre otros.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Detección de cuentas \"Fake\" de Instagram</span>"
    ]
  },
  {
    "objectID": "Análisis_Exploratorio.html",
    "href": "Análisis_Exploratorio.html",
    "title": "2  Análisis exploratorio de los datos",
    "section": "",
    "text": "2.1 Importación de las librerías y Dataset\nPrimero, antes de comenzar con el análisis exploratorio, importaremos todas las librerías necesarias para aplicar los diferentes datos, además de importar el Dataset train.csv.\nlibrary(tidyverse)  \n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr) \nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nlibrary(funModeling)   \n\nWarning: package 'funModeling' was built under R version 4.3.3\n\n\nLoading required package: Hmisc\n\n\nWarning: package 'Hmisc' was built under R version 4.3.3\n\n\n\nAttaching package: 'Hmisc'\n\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\nfunModeling v.1.9.5 :)\nExamples and tutorials at livebook.datascienceheroes.com\n / Now in Spanish: librovivodecienciadedatos.ai\n\ntrain &lt;- read_csv(\"train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nComo ya tenemos todo bien importado, comenzamos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análisis exploratorio de los datos</span>"
    ]
  },
  {
    "objectID": "Análisis_Exploratorio.html#análisis",
    "href": "Análisis_Exploratorio.html#análisis",
    "title": "2  Análisis exploratorio de los datos",
    "section": "2.2 Análisis",
    "text": "2.2 Análisis\nPrimero, vamos a ver un resumen de la estructura de nuestra tabla y visualizar las primeras y últimas filas de nuestro dataset.\n\nglimpse(train)\n\nRows: 576\nColumns: 12\n$ `profile pic`          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ `nums/length username` &lt;dbl&gt; 0.27, 0.00, 0.10, 0.00, 0.00, 0.00, 0.00, 0.00,…\n$ `fullname words`       &lt;dbl&gt; 0, 2, 2, 1, 2, 4, 2, 2, 0, 2, 2, 2, 2, 2, 2, 3,…\n$ `nums/length fullname` &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `name==username`       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `description length`   &lt;dbl&gt; 53, 44, 0, 82, 0, 81, 50, 0, 71, 40, 54, 54, 0,…\n$ `external URL`         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,…\n$ private                &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `#posts`               &lt;dbl&gt; 32, 286, 13, 679, 6, 344, 16, 33, 72, 213, 648,…\n$ `#followers`           &lt;dbl&gt; 1000, 2740, 159, 414, 151, 669987, 122, 1078, 1…\n$ `#follows`             &lt;dbl&gt; 955, 533, 98, 651, 126, 150, 177, 76, 2713, 813…\n$ fake                   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\nhead(train)\n\n# A tibble: 6 × 12\n  `profile pic` `nums/length username` `fullname words` `nums/length fullname`\n          &lt;dbl&gt;                  &lt;dbl&gt;            &lt;dbl&gt;                  &lt;dbl&gt;\n1             1                   0.27                0                      0\n2             1                   0                   2                      0\n3             1                   0.1                 2                      0\n4             1                   0                   1                      0\n5             1                   0                   2                      0\n6             1                   0                   4                      0\n# ℹ 8 more variables: `name==username` &lt;dbl&gt;, `description length` &lt;dbl&gt;,\n#   `external URL` &lt;dbl&gt;, private &lt;dbl&gt;, `#posts` &lt;dbl&gt;, `#followers` &lt;dbl&gt;,\n#   `#follows` &lt;dbl&gt;, fake &lt;dbl&gt;\n\n\n\ntail(train)\n\n# A tibble: 6 × 12\n  `profile pic` `nums/length username` `fullname words` `nums/length fullname`\n          &lt;dbl&gt;                  &lt;dbl&gt;            &lt;dbl&gt;                  &lt;dbl&gt;\n1             1                   0.2                 1                   0   \n2             1                   0.55                1                   0.44\n3             1                   0.38                1                   0.33\n4             1                   0.57                2                   0   \n5             1                   0.57                1                   0   \n6             1                   0.27                1                   0   \n# ℹ 8 more variables: `name==username` &lt;dbl&gt;, `description length` &lt;dbl&gt;,\n#   `external URL` &lt;dbl&gt;, private &lt;dbl&gt;, `#posts` &lt;dbl&gt;, `#followers` &lt;dbl&gt;,\n#   `#follows` &lt;dbl&gt;, fake &lt;dbl&gt;\n\n\nEl data set tiene las siguientes columnas:\n\nProfile pic: nos indica si el la cuenta tiene imagen de perfil.\nNums/length username: porcentaje de numeros que tiene el nombre de usuario\nFullname words: el numero de palaras que tiene el nombre completo de la cuenta\nNums/length full name: porcentaje de numeros que tiene el nombre comple\nName==username: nos indica si el nombre completo es igual al usuario\nDescription length: nos muestra el numero de caracteres que tiene la descripcion de la cuenta\nExternalURL: nos muestra si tiene una URL externa o no.\nPrivate: nos dice si la privacidad de la cuenta es pública(0) o privada(1)\nPosts: nos indica el número de posts que tiene la cuenta\nFollowers: nos dice el número de seguidores que tiene la cuenta\nFollows: nos indica el número de cuentas que sigue el usuario\nFake: es la columna más importante, nos dice si la cuenta es falsa o no.\n\nUna vez puestos en contexto, podemos comenzar con el análisis exploratorio.\nLo primero que debemos hacer es ver el numero de variable que almacena el dataset así como el numero de datos del que disponemos, además del estado de los mismo, es decir, ver si hay muchos na, sin hay muchos únicos, etc; para así poder descartar fácilmente aquellas columnas que no aportan ninguna información.\n\nncol(train)\n\n[1] 12\n\n\n\nnrow(train)\n\n[1] 576\n\n\n\nstatus(train)\n\n                                 variable q_zeros    p_zeros q_na p_na q_inf\nprofile pic                   profile pic     172 0.29861111    0    0     0\nnums/length username nums/length username     299 0.51909722    0    0     0\nfullname words             fullname words      57 0.09895833    0    0     0\nnums/length fullname nums/length fullname     518 0.89930556    0    0     0\nname==username             name==username     556 0.96527778    0    0     0\ndescription length     description length     326 0.56597222    0    0     0\nexternal URL                 external URL     509 0.88368056    0    0     0\nprivate                           private     356 0.61805556    0    0     0\n#posts                             #posts     157 0.27256944    0    0     0\n#followers                     #followers      18 0.03125000    0    0     0\n#follows                         #follows      11 0.01909722    0    0     0\nfake                                 fake     288 0.50000000    0    0     0\n                     p_inf    type unique\nprofile pic              0 numeric      2\nnums/length username     0 numeric     54\nfullname words           0 numeric      9\nnums/length fullname     0 numeric     25\nname==username           0 numeric      2\ndescription length       0 numeric    104\nexternal URL             0 numeric      2\nprivate                  0 numeric      2\n#posts                   0 numeric    193\n#followers               0 numeric    372\n#follows                 0 numeric    400\nfake                     0 numeric      2\n\n\nNinguna columna tiene datos NA, por lo que podemos decir que este dataset es completo.\nAdemás, podemos observar que la columna name==username tiene un 96% de porcentaje de 0s, lo cual nos puede dar algún indicio de que sea inservible. Sin embargo, lo dejaremos para ver que reglas nos salen con este atributo y decidiremos.\nPara saber en que datos nos estamos moviendo, me gustaría saber cual es la frecuencia de cuentas fake que tenemos. Para ellos vamos a utilizar el comando table.\n\ntable(train$fake)\n\n\n  0   1 \n288 288 \n\n\nComo puedes ver, la mitad de las cuentas en nuestro dataset son falsas. Así que ahora toca escarbar más profundo para entender qué las hace diferentes de las cuentas reales.\nSiguiendo el sentido común, normalmente las cuentas fake no suelen tener fotos de perfil, por lo que nuestro siguiente estudio se centrará en ver que ratio de cuentas fake no tienen foto de perfil, a ver si a priori tenemos razón.\n\nnumfotoPerfilFake &lt;- train %&gt;% filter(`profile pic` == 0 & fake == 1) %&gt;% nrow()\n\nnumDatosFake &lt;- train %&gt;% filter(fake == 1) %&gt;%  nrow()\nnumfotoPerfilFake/numDatosFake\n\n[1] 0.5902778\n\n\nTeniamos cierta razón, de todas las cuentas fakes, casi un 60% de ellas no tienen foto de perfil, por lo que pienso que este dato es importante para la detección de dichas cuentas.\nOtro dato muy a tener en cuenta son los seguidores de una cuenta, ya que la mayoría de cuentas falsas no tienen muchos seguidores. Vamos a ver si es cierto esto.\n\nmedfollowersFake &lt;- train %&gt;% filter(fake == 1) %&gt;% select(`#followers`)\nmedfollowersFake &lt;- mean(medfollowersFake$`#followers`)\n\nmedfollowersReal &lt;- train %&gt;% filter(fake == 0) %&gt;% select(`#followers`)\nmedfollowersReal &lt;- mean(medfollowersReal$`#followers`)\n\nmedfollowersFake\n\n[1] 110.5868\n\nmedfollowersReal\n\n[1] 170503.9\n\n\nLa diferencia de medias es bastante grande, mientras que la media de seguidores de las cuentas falsas son de 110.6 aproximadamente, la media de seguidores de las cuentas reales es de 170504. Esto nos afirma que una cuenta con un numero bajo de seguidores, tiene bastante probabilidad de ser una cuenta falsa, aunque no nos lo asegura al 100% ya que hay muchas cuentas reales con menos seguidores que la primera media.\nA continuación, vamos a comprobar que correlación tienen las cuentas fake con la longitud de las descripciones.\n\ncor(train$fake, train$`description length`)\n\n[1] -0.4608246\n\n\nComo podemos ver, un valor más alto en la variable fake tiende a estar asociado con una longitud más corta en la descripción del perfil en Instagram. Por lo tanto, podríamos inferir que las cuentas que tienen descripciones más cortas tienden a ser más propensas a ser falsas.\nHemos visto las relaciones entre algunas columnas de datos para saber un poco más que tipo de datos estamos manejando. Tras esto, vamos a visualizar todo lo que hemos visto en forma de gráficos, para poder ver las relaciones de los datos de una manera más simple y rápida.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análisis exploratorio de los datos</span>"
    ]
  },
  {
    "objectID": "Visualizacion.html",
    "href": "Visualizacion.html",
    "title": "3  Visualización de Datos",
    "section": "",
    "text": "3.1 Importación de las librerías y Dataset\nPrimero, antes de comenzar con la visualización de los datos, importaremos todas las librerías necesarias para aplicar los diferentes datos, además de importar el Dataset train.csv.\nlibrary(tidyverse)   \n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)  \nlibrary(magrittr) \n\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nlibrary(ggplot2)     \n\ntrain &lt;- read_csv(\"train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nComo ya tenemos todo bien importado, comenzamos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización de Datos</span>"
    ]
  },
  {
    "objectID": "Visualizacion.html#visualización",
    "href": "Visualizacion.html#visualización",
    "title": "3  Visualización de Datos",
    "section": "3.2 Visualización",
    "text": "3.2 Visualización\nA continuación, vamos a crear una variedad de grafos que nos van a ayudar a explorar y comunicar las relaciones entre las diferentes variables.\nPrimero visualizaremos la distribución de las variables numéricas como profile_pics, nums/length username.\n\ntrain %&gt;% group_by(`profile pic`) %&gt;% count() %&gt;%   \n  ggplot(aes(x= `profile pic`, y = n)) +  geom_bar(stat=\"identity\", fill=\"red\")\n\n\n\n\n\n\n\n\n\ntrain %&gt;% filter(`nums/length username`!= 0) %&gt;%  group_by(`nums/length username`)   %&gt;% count() %&gt;%  ggplot(aes(x= `nums/length username`, y = n)) + \n  geom_bar(stat=\"identity\", fill=\"red\")\n\n\n\n\n\n\n\n\nAhora realizaremos un bloxplot para comparar la distribución de una variable numérica entre diferentes grupos. Por ejemplo, followers por fake.\n\ntrain %&gt;% ggplot(aes(x=factor(fake), y=`#followers`)) +    \n  geom_boxplot(fill=\"lightblue\", color=\"darkblue\") +    \n  labs(title=\"Seguidores por Tipo de Cuenta\", x=\"Cuenta Fake\", y=\"Número de Seguidores\") +    \n  scale_x_discrete(labels=c(\"0\" = \"Real\", \"1\" = \"Fake\")) +    \n  facet_wrap(~ fake, scales = \"free\")\n\n\n\n\n\n\n\n\nAqui nos damos cuenta de que el numero de seguidores de una cuenta real es mucha mayor a la de las cuentas fake.\nA continuación, vamos a visualizar un scatter plot o diagrama de dispersión para explorar relaciones entre pares de variables numéricas, como followers vs posts. Como ambas variables tienen una gran variedad de datos distintos, vamos a agregar una línea de suavizado para capturar la tendencia general de los datos. Además, debido a la alta variabilidad y los valores extremos de las variables, voy a aplicar una transformación logarítmica para ayudar a visualizar mejor su relación.\n\ntrain %&gt;% ggplot(aes(x=log1p(`#followers`), y = log1p(`#posts` ))) +    \n  geom_point(alpha=0.4) +    \n  geom_smooth(method=\"loess\") +    \n  labs(title=\"Seguidores vs Posts con Suavizado\", x=\"Número de Seguidores\", y=\"Número de Posts\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAhora vamos a comprarar distribuciones de variables numéricas entre diferentes grupos utilizando gráficos de densidad.\n\ntrain %&gt;% ggplot( aes(x=`description length`, fill=factor(fake))) +   \n  geom_density(alpha=0.5) +    \n  labs(title=\"Densidad de Longitud de Descripción por Tipo de Cuenta\", x=\"Longitud de Descripción\", fill=\"Cuenta Fake\") \n\n\n\n\n\n\n\n\nDe esta gráfica podemos sacar varias conclusiones:\n\nLas cuentas falsas tienen tendencia a tener descripciones más cortas\nLas cuentas no falsas tienen una variedad más amplia en la longitud de sus descripciones\nLa densidad para las cuentas falsas es alta cuando la longitud de la descripción es corta, disminuyendo rápidamente a medida que aumenta la longitud.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización de Datos</span>"
    ]
  },
  {
    "objectID": "Reglas.html",
    "href": "Reglas.html",
    "title": "4  Reglas de Asociación",
    "section": "",
    "text": "4.1 Importación de las librerías y Dataset\nPrimero, antes de comenzar con el análisis de reglas de asociación, importaremos todas las librerías necesarias para aplicar los diferentes datos, además de importar el Dataset train.csv.\nlibrary(tidyverse)    \n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)   \nlibrary(magrittr)  \n\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nlibrary(arules)\n\nWarning: package 'arules' was built under R version 4.3.3\n\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nAttaching package: 'arules'\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nThe following objects are masked from 'package:base':\n\n    abbreviate, write\n\nlibrary(arulesViz)\n\nWarning: package 'arulesViz' was built under R version 4.3.3\n\ntrain &lt;- read_csv(\"train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nComo ya tenemos todo bien importado, comenzamos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reglas de Asociación</span>"
    ]
  },
  {
    "objectID": "Reglas.html#preparación",
    "href": "Reglas.html#preparación",
    "title": "4  Reglas de Asociación",
    "section": "4.2 Preparación",
    "text": "4.2 Preparación\nAl usar el método a priori, debemos convertir todas aquelas variables continuas y numéricas en categóricas, es decir, en factores. En nuestro caso al ser todas numéricas, habrá que cambiar todo, pero lo haremos en una copia, no en la original.\n\n#Creamos la copia\ntrain_factor &lt;- train\n\n\n# Foto de perfil\ntrain_factor$`profile pic` &lt;- as.factor(train_factor$`profile pic`)\n\n# Nombre = Nombre Usuario\ntrain_factor$`name==username` &lt;- as.factor(train_factor$`name==username`)\n\n# URL Externa\ntrain_factor$`external URL` &lt;- as.factor(train_factor$`external URL`)\n\n# Privado\ntrain_factor$private &lt;- as.factor(train_factor$private)\n\n# Fake\ntrain_factor$fake &lt;- as.factor(train_factor$fake)\n\n# nums/length username\ntrain_factor$`nums/length username` &lt;- ordered(cut(train_factor$`nums/length username`, \n                               breaks = c(-Inf, 0.1, 0.5, Inf), \n                               labels = c(\"Bajo\", \"Medio\", \"Alto\")))\n\n# nums/length fullname\ntrain_factor$`nums/length fullname` &lt;- ordered(cut(train_factor$`nums/length fullname`, \n                               breaks = c(-Inf, 0.1, 0.5, Inf), \n                               labels = c(\"Bajo\", \"Medio\", \"Alto\")))\n\n# fullname words \ntrain_factor$`fullname words` &lt;- ordered(cut(train_factor$`fullname words`, \n                         breaks = c(-Inf, 1, 4, Inf), \n                         labels = c(\"Corto\", \"Medio\", \"Largo\")))\n\n# description length\ntrain_factor$`description length` &lt;- ordered(cut(train_factor$`description length` , \n                             breaks = c(-Inf, 50, 100, Inf), \n                             labels = c(\"Corto\", \"Medio\", \"Largo\")))\n# #posts\n# Utilizaremos cuantiles debido a que la distribución de los datos, como hemos visto, no es uniforme\nbreaks_posts &lt;- unique(quantile(train_factor$`#posts`, probs = seq(0, 1, 0.25)))\n\ntrain_factor$`#posts` &lt;- ordered(cut(train_factor$`#posts`, \n                breaks = breaks_posts, \n                include.lowest = TRUE, \n                labels = c(\"Bajo\", \"Medio\", \"Alto\")))\n\n# #followers \nbreaks_followers &lt;- unique(quantile(train_factor$`#followers`, probs = seq(0, 1, 0.25)))\n                           \ntrain_factor$`#followers` &lt;- cut(train_factor$`#followers`, \n                    breaks = breaks_followers, \n                    include.lowest = TRUE, \n                    labels = c(\"Bajo\", \"Medio-Bajo\", \"Medio-Alto\", \"Alto\"))\n\n#  #follows \nbreaks_follows &lt;- unique(quantile(train_factor$`#follows`, probs = seq(0, 1, 0.25)))\n\ntrain_factor$`#follows` &lt;- cut(train_factor$`#follows`, \n                  breaks = breaks_follows, \n                  include.lowest = TRUE, \n                  labels = c(\"Bajo\", \"Medio-Bajo\", \"Medio-Alto\", \"Alto\"))\n\n#Guardamos la copia en un archivo\nwrite.csv(train_factor, \"train_factor.csv\")\n\nUna vez preparado nuestras variables, convertimos el tipo de datos a transacciones para poder realizar a priori.\n\ntrain_transactions &lt;- as(train_factor, \"transactions\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reglas de Asociación</span>"
    ]
  },
  {
    "objectID": "Reglas.html#extracción-de-reglas-por-el-método-a-priori",
    "href": "Reglas.html#extracción-de-reglas-por-el-método-a-priori",
    "title": "4  Reglas de Asociación",
    "section": "4.3 Extracción de reglas por el método a priori",
    "text": "4.3 Extracción de reglas por el método a priori\nVamos a realizar el método a priori para obtener las reglas de asociación, con un 15% de soporte mínimo y una confianza mínima del 80%.\n\ntrain_rules &lt;- apriori(train_transactions, parameter = list(supp = 0.15, conf = 0.8))  \n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support minlen\n        0.8    0.1    1 none FALSE            TRUE       5    0.15      1\n maxlen target  ext\n     10  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 86 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[33 item(s), 576 transaction(s)] done [0.00s].\nsorting and recoding items ... [25 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 4 5 6 7 8 done [0.00s].\nwriting ... [5333 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\n# Ordenamos por confianza \ntrain_rules &lt;- sort(train_rules, by = \"confidence\")\n\nHemos obtenido un total de 5333 reglas.\nPara conocer un poco más que reglas e itemset hemos sacado, vamos a visualizar los itemsets más frecuentes.\n\nbarplot(table(size(train_rules)),         \n        xlab = \"Tamaño de itemset\", ylab = \"Frecuencia\",         \n        main = \"Tamaños de itemsets en los itemsets frecuentes\")\n\n\n\n\n\n\n\n\nAntes de seguir analizando las diferentes reglas, vamos a eliminar las reglas que son redundantes, es decir, reglas que están incluidas en otras.\n\ntrain_rules_pruned &lt;- train_rules[which(!is.redundant(train_rules))]\n\nA continuación eliminaremos aquella reglas con confianza == 1 ya que el objetivo de este análisis es descubrir relaciones no triviales o patrones inesperados, por lo que las verdades absolutas no nos interesan.\n\ntrain_rules_selected &lt;- subset(train_rules_pruned, subset = confidence &lt; 1)\n\nPara la obtención de relaciones no triviales y de las asociaciones más útiles, vamos a escoger aquellas reglas cuyo lift sea &gt; 1 y ordenaremos por lift para obtener las más útiles.\n\ntrain_rules_selected &lt;- subset(train_rules_selected, subset = lift &gt; 1)  \ntrain_rules_selected &lt;- sort(train_rules_selected, by = \"lift\")  \n\ninspect(head(train_rules_selected, 10))\n\n     lhs                             rhs             support confidence  coverage     lift count\n[1]  {profile pic=1,                                                                            \n      nums/length username=Bajo,                                                                \n      #followers=Alto}            =&gt; {fake=0}      0.2031250  0.9915254 0.2048611 1.983051   117\n[2]  {nums/length username=Bajo,                                                                \n      name==username=0,                                                                         \n      #followers=Alto}            =&gt; {fake=0}      0.2031250  0.9915254 0.2048611 1.983051   117\n[3]  {nums/length username=Bajo,                                                                \n      private=0,                                                                                \n      #posts=Alto}                =&gt; {fake=0}      0.1545139  0.9888889 0.1562500 1.977778    89\n[4]  {profile pic=0}              =&gt; {fake=1}      0.2951389  0.9883721 0.2986111 1.976744   170\n[5]  {profile pic=0,                                                                            \n      #followers=Bajo}            =&gt; {#posts=Bajo} 0.1666667  0.9896907 0.1684028 1.972532    96\n[6]  {fullname words=Corto,                                                                     \n      #followers=Bajo}            =&gt; {fake=1}      0.2135417  0.9840000 0.2170139 1.968000   123\n[7]  {nums/length username=Bajo,                                                                \n      #posts=Alto}                =&gt; {fake=0}      0.2118056  0.9838710 0.2152778 1.967742   122\n[8]  {nums/length username=Bajo,                                                                \n      #followers=Alto}            =&gt; {fake=0}      0.2031250  0.9831933 0.2065972 1.966387   117\n[9]  {private=0,                                                                                \n      #posts=Alto}                =&gt; {fake=0}      0.1684028  0.9797980 0.1718750 1.959596    97\n[10] {#posts=Alto,                                                                              \n      #followers=Alto}            =&gt; {fake=0}      0.1631944  0.9791667 0.1666667 1.958333    94\n\n\nComo podemos observar, de estas 10 reglas más útiles, las que verdaderamente nos importan son:\n\nprofile pic = 0 -&gt; fake = 1\nfullname words = Corto, #followers = Bajo -&gt; fake = 1\n\nEs decir, lo que nos importa verdaderamente son aquellas reglas cuya parte derecha sea fake = 1, por lo que vamos a filtrarlo para ver que obtenemos.\n\ntrain_rules_fake  &lt;- subset(train_rules_selected, train_rules_selected@rhs %in% \"fake=1\")  \n\ninspect(head(train_rules_fake, 10))\n\n     lhs                              rhs        support confidence  coverage     lift count\n[1]  {profile pic=0}               =&gt; {fake=1} 0.2951389  0.9883721 0.2986111 1.976744   170\n[2]  {fullname words=Corto,                                                                 \n      #followers=Bajo}             =&gt; {fake=1} 0.2135417  0.9840000 0.2170139 1.968000   123\n[3]  {nums/length username=Medio,                                                           \n      fullname words=Corto,                                                                 \n      nums/length fullname=Bajo,                                                            \n      #posts=Bajo}                 =&gt; {fake=1} 0.1718750  0.9705882 0.1770833 1.941176    99\n[4]  {fullname words=Corto,                                                                 \n      nums/length fullname=Bajo,                                                            \n      description length=Corto,                                                             \n      private=0,                                                                            \n      #posts=Bajo}                 =&gt; {fake=1} 0.1718750  0.9705882 0.1770833 1.941176    99\n[5]  {nums/length username=Medio,                                                           \n      fullname words=Corto,                                                                 \n      #posts=Bajo}                 =&gt; {fake=1} 0.2274306  0.9703704 0.2343750 1.940741   131\n[6]  {fullname words=Corto,                                                                 \n      description length=Corto,                                                             \n      private=0,                                                                            \n      #posts=Bajo}                 =&gt; {fake=1} 0.2100694  0.9680000 0.2170139 1.936000   121\n[7]  {#followers=Bajo}             =&gt; {fake=1} 0.2447917  0.9657534 0.2534722 1.931507   141\n[8]  {fullname words=Corto,                                                                 \n      #posts=Bajo,                                                                          \n      #follows=Bajo}               =&gt; {fake=1} 0.1770833  0.9622642 0.1840278 1.924528   102\n[9]  {fullname words=Corto,                                                                 \n      nums/length fullname=Bajo,                                                            \n      private=0,                                                                            \n      #posts=Bajo}                 =&gt; {fake=1} 0.1736111  0.9615385 0.1805556 1.923077   100\n[10] {fullname words=Corto,                                                                 \n      private=0,                                                                            \n      #posts=Bajo}                 =&gt; {fake=1} 0.2118056  0.9606299 0.2204861 1.921260   122\n\n\nVamos a visualizar gráficamente estas reglas.\n\nplot(train_rules_fake, method = \"graph\", control = list(type = \"items\"))\n\nWarning: Unknown control parameters: type\n\n\nAvailable control parameters (with default values):\nlayout   =  stress\ncircular     =  FALSE\nggraphdots   =  NULL\nedges    =  &lt;environment&gt;\nnodes    =  &lt;environment&gt;\nnodetext     =  &lt;environment&gt;\ncolors   =  c(\"#EE0000FF\", \"#EEEEEEFF\")\nengine   =  ggplot2\nmax  =  100\nverbose  =  FALSE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reglas de Asociación</span>"
    ]
  },
  {
    "objectID": "Reglas.html#conclusión-y-recomendaciones",
    "href": "Reglas.html#conclusión-y-recomendaciones",
    "title": "4  Reglas de Asociación",
    "section": "4.4 Conclusión y Recomendaciones",
    "text": "4.4 Conclusión y Recomendaciones\nCon todos estos datos, las recomendaciones que podemos dar para reconocer fácilmente las cuentas fakes son:\n\nMonitorear aquellas cuentas sin foto de perfil, ya que según hemos comprobado tienen una confianzadel 98% y tienen 1,98 más probabilidad de ser fake que las demás\nHacer incapié en aquellas cuentas con nombre completo corto, ya que pertenece a la mayor parte reglas, realizando un análisis más profundo de otras caracteristicas como la descripcion, numero de posts, su privacidad, entre otros.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reglas de Asociación</span>"
    ]
  },
  {
    "objectID": "FCA.html",
    "href": "FCA.html",
    "title": "5  FCA - Formal Concept Analysis",
    "section": "",
    "text": "5.1 Importación de las librerías y Dataset\nPrimero, antes de comenzar con el análisis de conceptos formales, importaremos todas las librerías necesarias para aplicar los diferentes datos, además de importar el Dataset train.csv.\nlibrary(tidyverse) \n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)  \nlibrary(magrittr)  \n\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nlibrary(fcaR)\n\nWarning: package 'fcaR' was built under R version 4.3.3\n\n\n\nAttaching package: 'fcaR'\n\nThe following object is masked from 'package:purrr':\n\n    as_vector\n\ntrain_factor  &lt;- read_csv(\"train_factor.csv\")\n\nNew names:\nRows: 576 Columns: 13\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(7): nums/length username, fullname words, nums/length fullname, descrip... dbl\n(6): ...1, profile pic, name==username, external URL, private, fake\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\nComo ya tenemos todo bien importado, comenzamos.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>FCA - Formal Concept Analysis</span>"
    ]
  },
  {
    "objectID": "FCA.html#preparación",
    "href": "FCA.html#preparación",
    "title": "5  FCA - Formal Concept Analysis",
    "section": "5.2 Preparación",
    "text": "5.2 Preparación\nAl haber factorizado los datos, vamos a trabajar sobre los mismos, ya que al hacer el proceso de scaling nos van a salir mejores resultados con categorías discretas que con datos númericos diferentes.\n\n5.2.1 Contexto Formal\nPrimero, como ya tenemos los datos categorizados, crearemos el contexto formal.\n\ntrain_factor$...1 &lt;- NULL\ncontexto_train &lt;- FormalContext$new(train_factor)\ncontexto_train\n\nFormalContext with 576 objects and 12 attributes.\n# A tibble: 576 × 12\n   `profile pic` `nums/length username` `fullname words` `nums/length fullname`\n           &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;            &lt;chr&gt;                 \n 1             1 Medio                  Corto            Bajo                  \n 2             1 Bajo                   Medio            Bajo                  \n 3             1 Bajo                   Medio            Bajo                  \n 4             1 Bajo                   Corto            Bajo                  \n 5             1 Bajo                   Medio            Bajo                  \n 6             1 Bajo                   Medio            Bajo                  \n 7             1 Bajo                   Medio            Bajo                  \n 8             1 Bajo                   Medio            Bajo                  \n 9             1 Bajo                   Corto            Bajo                  \n10             1 Bajo                   Medio            Bajo                  \n# ℹ 566 more rows\n# ℹ 8 more variables: `name==username` &lt;dbl&gt;, `description length` &lt;chr&gt;,\n#   `external URL` &lt;dbl&gt;, private &lt;dbl&gt;, `#posts` &lt;chr&gt;, `#followers` &lt;chr&gt;,\n#   `#follows` &lt;chr&gt;, fake &lt;dbl&gt;\n\n\n\n\n5.2.2 Scaling\nRealizamos esto porque nos ayuda a transformar los datos en un formato adecuado para el análisis conceptual, es decir, en un formato binario.\n\ncontexto_train$scale(\"profile pic\", \"Nominal\")\ncontexto_train$scale(\"external URL\", \"Nominal\") \ncontexto_train$scale(\"private\", \"Nominal\") \ncontexto_train$scale(\"fake\", \"Nominal\") \ncontexto_train$scale(\"name==username\", \"Nominal\") \ncontexto_train$scale(\"nums/length username\", \"Ordinal\") \ncontexto_train$scale(\"nums/length fullname\", \"Ordinal\") \ncontexto_train$scale(\"fullname words\", \"Ordinal\") \ncontexto_train$scale(\"description length\", \"Ordinal\")\ncontexto_train$scale(\"#posts\", \"Ordinal\") \ncontexto_train$scale(\"#follows\", \"Ordinal\") \ncontexto_train$scale(\"#followers\", \"Ordinal\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>FCA - Formal Concept Analysis</span>"
    ]
  },
  {
    "objectID": "FCA.html#aplicación-de-fca",
    "href": "FCA.html#aplicación-de-fca",
    "title": "5  FCA - Formal Concept Analysis",
    "section": "5.3 Aplicación de FCA",
    "text": "5.3 Aplicación de FCA\nAhora que tenemos los datos en formato binario, podemos proceder con el análisis FCA.\nPrimero, vamos a calcular y visualizar los diferentes conceptos que podemos obtener de estos datos. Mátematicamente, un concepto es un un par (X,Y) con X ⊆ O e Y ⊆ A, donde O es el conjunto de objetos y A el conjunto de atributos.\n\ncontexto_train$find_concepts()\nconceptos &lt;- contexto_train$concepts\nhead(conceptos, 3)\n\nA set of 3 concepts:\n1: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576}, {nums/length username &lt;= Medio, fullname words &lt;= Medio, nums/length fullname &lt;= Medio, description length &lt;= Medio, #posts &lt;= Medio, #followers &lt;= Medio-Bajo, #follows &lt;= Medio-Bajo})\n2: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288}, {nums/length username &lt;= Medio, fullname words &lt;= Medio, nums/length fullname &lt;= Medio, description length &lt;= Medio, #posts &lt;= Medio, #followers &lt;= Medio-Bajo, #follows &lt;= Medio-Bajo, fake = 0})\n3: ({1, 2, 4, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 31, 32, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 106, 107, 108, 109, 111, 112, 115, 116, 117, 118, 119, 120, 122, 123, 126, 128, 130, 131, 132, 133, 134, 136, 137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 184, 185, 186, 187, 188, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 218, 219, 220, 221, 223, 224, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 239, 241, 242, 244, 245, 246, 247, 248, 250, 251, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 289, 290, 291, 293, 295, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 309, 310, 311, 312, 313, 314, 316, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 336, 337, 339, 340, 341, 342, 343, 344, 346, 349, 350, 351, 353, 354, 355, 356, 357, 359, 360, 361, 366, 367, 369, 371, 373, 374, 377, 378, 379, 380, 382, 384, 385, 386, 387, 388, 389, 390, 392, 394, 398, 399, 401, 403, 408, 409, 412, 414, 418, 420, 421, 423, 425, 426, 428, 430, 432, 434, 436, 437, 441, 442, 443, 445, 447, 449, 451, 452, 454, 455, 456, 460, 461, 462, 464, 466, 467, 468, 469, 470, 471, 472, 473, 475, 476, 478, 479, 480, 481, 482, 483, 485, 486, 487, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 522, 523, 524, 525, 526, 527, 529, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 547, 549, 551, 552, 553, 554, 556, 557, 558, 559, 563, 565, 566, 567, 570, 572, 574, 576}, {nums/length username &lt;= Medio, fullname words &lt;= Medio, nums/length fullname &lt;= Medio, description length &lt;= Medio, #posts &lt;= Medio, #followers &lt;= Medio-Bajo, #follows &lt;= Medio-Alto, #follows &lt;= Medio-Bajo})\n\n\nComo podemos ver, al existir tantos datos, los conceptos no son fácilmente identificables . Además, al ser los objetos las distinas cuentas, tenemos una gran cantidad de filas que al intentar investigar patrones con extent o intent, es casi imposible sacar alguna conclusión firme de ellos.\nPor lo que la mejor opción para encontrar reglas o patrones es a través de las implicaciones.\n\ncontexto_train$find_implications()\nl &lt;- contexto_train$implications$size()\ncolMeans(l)\n\n      LHS       RHS \n14.686842  1.768421 \n\n\nSin aplicar reglas, obtenemos implicaciones con 14 objetos de media en la parte izquierda y 1,76 en la parte derecha. Vamos a ver ahora que pasa cuando le aplicamos reglas de generalización y simplicación\n\ncontexto_train$implications$apply_rules(rules = c(\"composition\",\n                                      \"generalization\",\n                                      \"simplification\",\n                                      \"rsimplification\"))\n\nProcessing batch\n\n\n--&gt; Composition: from 380 to 380.\n\n\n--&gt; Generalization: from 380 to 380.\n\n\n--&gt; Simplification: from 380 to 380.\n\n\n--&gt; Right Simplification: from 380 to 380.\n\nl &lt;- contexto_train$implications$size()\ncolMeans(l)\n\n     LHS      RHS \n4.015789 1.186842 \n\n\nComo vemos, la parte izquierda ha disminuido considerablemente, por lo que nos será más fácil trabajar con ellas.\nComo el objetivo de este análisis son las cuentas fake, por lo que vamos a filtrar a ver que nos encontramos.\n\ncontexto_train$implications$filter(rhs = \"fake = 1\")\n\nImplication set with 4 implications.\nRule 1: {name==username = 1, #posts &lt;= Bajo} -&gt; {fake = 1}\nRule 2: {nums/length username &lt;= Alto} -&gt; {nums/length username &lt;= Bajo,\n  description length &lt;= Corto, fake = 1}\nRule 3: {profile pic = 0, #followers &lt;= Bajo} -&gt; {#posts &lt;= Bajo, fake = 1}\nRule 4: {profile pic = 0, private = 0} -&gt; {description length &lt;= Corto, fake =\n  1}",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>FCA - Formal Concept Analysis</span>"
    ]
  },
  {
    "objectID": "FCA.html#conclusiones",
    "href": "FCA.html#conclusiones",
    "title": "5  FCA - Formal Concept Analysis",
    "section": "5.4 Conclusiones",
    "text": "5.4 Conclusiones\nAl hacer todas estas operaciones, hemos conseguido obtener resultados bastante interesantes. También hay que decir que estas reglas no tienen un 100% de confianza, ya que éstas se adaptan a los datos que tenemos, que aunque hay bastantes, no son suficiente para darnos verdades “absolutas”. Sin embargo nos dan una buena visión sobre que características hay que tener más en cuenta para la detección de las cuentas falsas.\nLa información más relevante que hemos sacado de estas implicaciones son:\n\nParece ser que con los datos que tenemos, si una cuenta tiene el mismo nombre tanto de usuario como completo, además de tener un número bajo de posts, siempre es fake.\nOtra regla importante a tener en cuenta es la tercera, la cual nos dice que si la cuenta no tiene foto de perfil y el número de seguidores es bajo o muy bajo, la cuenta sera fake y la descripcion será corta.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>FCA - Formal Concept Analysis</span>"
    ]
  },
  {
    "objectID": "Regresion.html",
    "href": "Regresion.html",
    "title": "6  Modelos de Regresión",
    "section": "",
    "text": "6.1 Importación de las librerías y Dataset\nPrimero, antes de comenzar con la realización de los modelos de regresión, importaremos todas las librerías necesarias para aplicar los diferentes datos, además de importar el Dataset train.csv.\nlibrary(tidyverse)\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)  \nlibrary(magrittr) \n\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\nComo ya tenemos todo bien importado, comenzamos.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de Regresión</span>"
    ]
  },
  {
    "objectID": "Regresion.html#modelado-de-regresión",
    "href": "Regresion.html#modelado-de-regresión",
    "title": "6  Modelos de Regresión",
    "section": "6.2 Modelado de Regresión",
    "text": "6.2 Modelado de Regresión\n\n6.2.1 División de datos\nPara trabajar correctamente con los datos, vamos a dividirlos en dos grupos, train y test.\n\ntrain &lt;- read_csv(\"train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntest &lt;- read_csv(\"test.csv\")\n\nRows: 120 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCon el dataset train es con el que realizaremos nuestro modelo, mientras que con el dataset test es con el que realizaremos las pruebas y predicciones.\n\n\n6.2.2 Ajuste del modelo de regresión y evaluación\nUna vez dividido los datos, procederemos a ajustar un modelo de regresión con los datos de train. Al investigar las cuentas fake de Instagram, la variable dependiente de nuestro modelo será el atributo fake. Primero relacionaremos esa variable con todas las demás, para ver cuáles son significativas.\n\nattach(train)\nmodelo1 &lt;- lm(fake ~ ., data = train)\nsummary(modelo1)\n\n\nCall:\nlm(formula = fake ~ ., data = train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.73096 -0.23729 -0.06653  0.24048  1.01052 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             7.931e-01  3.798e-02  20.880  &lt; 2e-16 ***\n`profile pic`          -4.380e-01  3.345e-02 -13.094  &lt; 2e-16 ***\n`nums/length username`  8.062e-01  7.522e-02  10.718  &lt; 2e-16 ***\n`fullname words`       -3.354e-02  1.333e-02  -2.516 0.012142 *  \n`nums/length fullname` -2.775e-02  1.212e-01  -0.229 0.818988    \n`name==username`        2.241e-01  7.641e-02   2.933 0.003498 ** \n`description length`   -1.510e-03  4.342e-04  -3.478 0.000544 ***\n`external URL`         -1.542e-01  4.800e-02  -3.213 0.001390 ** \nprivate                -9.459e-03  2.843e-02  -0.333 0.739459    \n`#posts`               -9.094e-05  3.570e-05  -2.547 0.011120 *  \n`#followers`           -9.960e-09  1.539e-08  -0.647 0.517743    \n`#follows`             -1.850e-05  1.499e-05  -1.235 0.217530    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3166 on 564 degrees of freedom\nMultiple R-squared:  0.6074,    Adjusted R-squared:  0.5998 \nF-statistic: 79.33 on 11 and 564 DF,  p-value: &lt; 2.2e-16\n\n\nDe este modelo podemos sacar lo siguiente:\n\nAl ser el p-value bastante bajo, podemos decir que tenemos modelo.\nEl error estándar residual es relativamente bajo, por lo que nos puede dar un indicio de que las predicciones pueden ser buenas.\nEn este caso al ser un contexto social y tener una variablilidad alta, es un buen valor por lo que el error se ajusta parcialmente a los datos.\nAl ser el R2 ajustado cercano al estadístico anterior, sugiere que el modelo no está sobreajustado y que la mayoría de las variables incluidas son relevamtes.\n\nSin embargo, tenemos bastantes variables no significativas, lo que significa que si se eliminan, el modelo apenas no cambia. Para comprobarlo, vamos a hacer un segundo modelo, sin las variables no significativas, solo quedándonos con las muy significativas y las significativas.\n\nmodelo2 &lt;- lm(fake ~ `profile pic` + `nums/length username` + `description length` + `name==username` + `external URL`)\nsummary(modelo2)\n\n\nCall:\nlm(formula = fake ~ `profile pic` + `nums/length username` + \n    `description length` + `name==username` + `external URL`)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.71113 -0.24453 -0.07143  0.24282  0.98317 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.7354681  0.0316443  23.242  &lt; 2e-16 ***\n`profile pic`          -0.4596554  0.0328023 -14.013  &lt; 2e-16 ***\n`nums/length username`  0.8445023  0.0687052  12.292  &lt; 2e-16 ***\n`description length`   -0.0017381  0.0004285  -4.056 5.68e-05 ***\n`name==username`        0.2314540  0.0733411   3.156 0.001685 ** \n`external URL`         -0.1731966  0.0477099  -3.630 0.000309 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3196 on 570 degrees of freedom\nMultiple R-squared:  0.5956,    Adjusted R-squared:  0.592 \nF-statistic: 167.9 on 5 and 570 DF,  p-value: &lt; 2.2e-16\n\n\nComo podemos observar, efectivamente este modelo es prácticamente igual que el anterior, aún elimando variables independientes.\n\n\n6.2.3 Validación del modelo\nAhora lo que haremos será evaluar el segundo modelo obtenido.\n\n6.2.3.1 Visualización\nPara la validación del modelo, primero vamos a dibujarlo y analizarlo.\n\nplot(modelo2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTras ver la primera gráfica, podemos saber que los residuos no se esparcen aleatoriamente, si no que siguen un patrón que es fácilmente visible. Esto nos indica que el modelo de regresión lineal actual no es adecuado para los datos. Por lo tanto es importante reconsiderar la especificación del modelo, adoptando métodos de modelado alternativos para capturar mejor la relación entre los datos.\nLa última gráfica nos enseña los puntos que tienen más influencia en el modelo. Como podemos ver, algunos puntos de datos están influyendo desproporcionadamente en el modelo de regresión. Una buena solución es eliminar esos datos de nuestro dataset , volver a realizar el modelo y repetir este proceso. Además, se puede observar que los residuos están agrupados formando un patrón, posiblemente causado por la violación de supuestos del modelo.\n\n\n6.2.3.2 Evaluación en el conjunto de prueba\nAhora, usando el modelo entrenado, vamos a predecir los valores en el conjunto de prueba, a ver que estadísticos obtenemos y así podemos comprobar si nuestro modelo tiene un buen rendimiento con respecto al conjunto de prueba.\n\npredictions &lt;- predict(modelo2, newdata = test)\npredictions &lt;- ifelse(predictions &lt; 0.5, 0, 1)\n\nmse &lt;- mean((test$fake - predictions)^2)\nmse \n\n[1] 0.1083333\n\nmae &lt;- mean(abs(test$fake - predictions))\nmae\n\n[1] 0.1083333\n\nr_squared &lt;- 1 - sum((test$fake - predictions)^2) / sum((test$fake - mean(test$fake))^2)\nr_squared\n\n[1] 0.5666667\n\n\nMSE (Error cuadrático medio)\n\nEl mse mide el promedio de los cuadrados de los errores o desviaciones, es decir, la diferencia entre los valores observados y los predichos.\nEn este caso hemos obtenido un mse de 0.10. Sin embargo, este valor es demasiado alto, ya que el atributo fake toma valores entre 0 y 1, por lo que nos está indicando que no se ajusta relativamente bien al modelo\n\nMAE (Error absoluto medio)\n\nEL mae mide el promedio de los errores absolutos entre los valores observados y los predichos. Es más robusto a outliers en comparación con el mse.\nEn nuestro caso hemos obtenido un mae de 0.10, el cuál es el mismo que el mse, por lo que ocurre lo mismo\n\nR2\n\nIndica la proporción de la varianza en la variable dependiente que es predecible a partir de las variables independientes. Un R2 cercano a 1 indica un buen ajuste del modelo.\nEn este caso el R2 es bastante escaso, un 0.56. Lo que nos vuelve a indicar un mal ajuste a los datos del modelo.\n\n\n\n\n6.2.4 Mejora del modelo\nAl obtener unos resultados bastantes mediocres en la validación del modelo, vamos a mejorarlo añadiendo variables polinómicas. Iremos probando algunas hasta encontrar la combinación óptima que mejore nuestro modelo al completo.\n\n6.2.4.1 Ingeniería de Características\nPara intentar mejorar aun más el modelo, con los datos y variables que disponemos, vamos a intentar sacar nuevas variables operando con las existentes. Por ejemplo, vamos a ver si añadiendo una característica que sea followers/follows podemos mejorar el modelo.\n\ntrain$new_feature &lt;- train$`#follows`/ train$`#followers`\ntrain$new_feature2 &lt;- train$`description length`/ train$`#followers`\n\n\n#Eliminamos los infinitos\ntrain &lt;- train %&gt;% filter(new_feature != Inf) %&gt;% filter(new_feature2 != Inf)\n\nattach(train)\n\nThe following objects are masked from train (pos = 3):\n\n    #followers, #follows, #posts, description length, external URL,\n    fake, fullname words, name==username, nums/length fullname,\n    nums/length username, private, profile pic\n\nmodelo2.update &lt;- update(modelo2, . ~ . + new_feature + new_feature2)\nsummary(modelo2.update)\n\n\nCall:\nlm(formula = fake ~ `profile pic` + `nums/length username` + \n    `description length` + `name==username` + `external URL` + \n    new_feature + new_feature2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.67071 -0.23077 -0.06686  0.18271  1.01721 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.681296   0.033468  20.356  &lt; 2e-16 ***\n`profile pic`          -0.434518   0.033422 -13.001  &lt; 2e-16 ***\n`nums/length username`  0.854855   0.068426  12.493  &lt; 2e-16 ***\n`description length`   -0.001788   0.000428  -4.177 3.44e-05 ***\n`name==username`        0.257906   0.073403   3.514 0.000479 ***\n`external URL`         -0.146429   0.046858  -3.125 0.001872 ** \nnew_feature             0.007180   0.001692   4.243 2.59e-05 ***\nnew_feature2            0.006263   0.002161   2.899 0.003897 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3119 on 550 degrees of freedom\nMultiple R-squared:  0.616, Adjusted R-squared:  0.6111 \nF-statistic:   126 on 7 and 550 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n6.2.4.2 Selección de variables\nTal y como hemos estudiando anteriormente, una variable clave para detectar si una cuenta es falsa o no es el numero de palabras que tiene el nombre, así que vamos a añadirle a nuestro modelo esa variable polinómica a ver que ocurre.\n\nmodelo2.update &lt;- update(modelo2.update, . ~ . + I(`fullname words`^2))\nsummary(modelo2.update)\n\n\nCall:\nlm(formula = fake ~ `profile pic` + `nums/length username` + \n    `description length` + `name==username` + `external URL` + \n    new_feature + new_feature2 + I(`fullname words`^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.67437 -0.23185 -0.06312  0.18688  1.02784 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.6844401  0.0337092  20.304  &lt; 2e-16 ***\n`profile pic`          -0.4333272  0.0334664 -12.948  &lt; 2e-16 ***\n`nums/length username`  0.8517165  0.0685604  12.423  &lt; 2e-16 ***\n`description length`   -0.0017457  0.0004313  -4.047 5.92e-05 ***\n`name==username`        0.2559699  0.0734672   3.484 0.000533 ***\n`external URL`         -0.1456509  0.0468834  -3.107 0.001990 ** \nnew_feature             0.0071451  0.0016933   4.220 2.86e-05 ***\nnew_feature2            0.0061890  0.0021632   2.861 0.004383 ** \nI(`fullname words`^2)  -0.0013234  0.0016543  -0.800 0.424078    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.312 on 549 degrees of freedom\nMultiple R-squared:  0.6164,    Adjusted R-squared:  0.6109 \nF-statistic: 110.3 on 8 and 549 DF,  p-value: &lt; 2.2e-16\n\n\nComo vemos no cambia en nada, por lo que hay que seguir probando hasta dar con una mejora correcta.\n\nmodelo2.update &lt;- update(modelo2.update, . ~ . - I(`fullname words`^2) + I(`description length`^2) + I(`nums/length username`^2) + `nums/length username` * `#posts` + I(`nums/length username`^2) * `#posts` - `#posts` + I(new_feature^2))\nsummary(modelo2.update)\n\n\nCall:\nlm(formula = fake ~ `profile pic` + `nums/length username` + \n    `description length` + `name==username` + `external URL` + \n    new_feature + new_feature2 + I(`description length`^2) + \n    I(`nums/length username`^2) + I(new_feature^2) + `nums/length username`:`#posts` + \n    I(`nums/length username`^2):`#posts`)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.70635 -0.19447 -0.05844  0.14044  0.87632 \n\nCoefficients:\n                                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                           6.190e-01  3.402e-02  18.195  &lt; 2e-16 ***\n`profile pic`                        -3.715e-01  3.233e-02 -11.491  &lt; 2e-16 ***\n`nums/length username`                1.499e+00  1.605e-01   9.338  &lt; 2e-16 ***\n`description length`                 -6.842e-03  1.084e-03  -6.312 5.71e-10 ***\n`name==username`                      2.251e-01  6.842e-02   3.290  0.00107 ** \n`external URL`                       -1.277e-01  4.378e-02  -2.916  0.00369 ** \nnew_feature                           2.315e-02  3.925e-03   5.899 6.42e-09 ***\nnew_feature2                          3.243e-03  2.036e-03   1.593  0.11184    \nI(`description length`^2)             4.445e-05  8.327e-06   5.339 1.38e-07 ***\nI(`nums/length username`^2)          -1.137e+00  2.353e-01  -4.832 1.76e-06 ***\nI(new_feature^2)                     -2.290e-04  4.858e-05  -4.714 3.09e-06 ***\n`nums/length username`:`#posts`      -3.992e-03  1.388e-03  -2.876  0.00418 ** \nI(`nums/length username`^2):`#posts`  6.912e-03  3.680e-03   1.878  0.06088 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2898 on 545 degrees of freedom\nMultiple R-squared:  0.6715,    Adjusted R-squared:  0.6643 \nF-statistic: 92.85 on 12 and 545 DF,  p-value: &lt; 2.2e-16\n\n\nTras unos intentos, he llegado a la conclusión que este modelo no se puede mejorar más. Una de las causas es porque, de las variables significativas, si su valor es o 0 o 1, no tiene sentido elevarlo a algún numero, ya que se va a mantener igual. Otra de las causas es que del resto de variables numericas con mayor rango de números, si esas variables no son significativas en nuestro modelo, difícilmente lo serán en nuestro modelo polinómico.\nPor tanto, hemos conseguido mejorar nuestro modelo a un error estándar de residuos de 0.29 y a un R2 de 0.6715, 0.08 más que el anterior.\n\n\n6.2.4.3 Interpretación y Visualización\n\ncoef(summary(modelo2.update))\n\n                                          Estimate   Std. Error    t value\n(Intercept)                           6.189670e-01 3.401933e-02  18.194568\n`profile pic`                        -3.715207e-01 3.233134e-02 -11.491037\n`nums/length username`                1.499217e+00 1.605420e-01   9.338473\n`description length`                 -6.841723e-03 1.083921e-03  -6.312013\n`name==username`                      2.251309e-01 6.842475e-02   3.290196\n`external URL`                       -1.276772e-01 4.378434e-02  -2.916048\nnew_feature                           2.315379e-02 3.925037e-03   5.899001\nnew_feature2                          3.242557e-03 2.036056e-03   1.592568\nI(`description length`^2)             4.445164e-05 8.326533e-06   5.338553\nI(`nums/length username`^2)          -1.136992e+00 2.353216e-01  -4.831652\nI(new_feature^2)                     -2.290004e-04 4.857870e-05  -4.714008\n`nums/length username`:`#posts`      -3.991730e-03 1.387908e-03  -2.876077\nI(`nums/length username`^2):`#posts`  6.911970e-03 3.680055e-03   1.878225\n                                         Pr(&gt;|t|)\n(Intercept)                          3.745647e-58\n`profile pic`                        1.622660e-27\n`nums/length username`               2.470245e-19\n`description length`                 5.711863e-10\n`name==username`                     1.065887e-03\n`external URL`                       3.690902e-03\nnew_feature                          6.424652e-09\nnew_feature2                         1.118370e-01\nI(`description length`^2)            1.377207e-07\nI(`nums/length username`^2)          1.762628e-06\nI(new_feature^2)                     3.088344e-06\n`nums/length username`:`#posts`      4.184069e-03\nI(`nums/length username`^2):`#posts` 6.088409e-02\n\nplot(modelo2.update)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning in sqrt(crit * p * (1 - hh)/hh): Se han producido NaNs\n\nWarning in sqrt(crit * p * (1 - hh)/hh): Se han producido NaNs\n\n\n\n\n\n\n\n\n\nComo podemos observar, al final nos hemos quedado con 10 variables, de las cuales dos de ellas son polinómicas.\nDicho anteriormente, aunque hemos ligeramente mejorado nuestro modelo, no podemos considerarlo como un buen modelo debido a que su R2 sigue siendo aún muy bajo. Además los residuos siguen siguiendo un patrón, no son aleatorios, por lo que en esa parte tampoco hemos mejorado.\n\n\n\n6.2.5",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de Regresión</span>"
    ]
  },
  {
    "objectID": "Series.html",
    "href": "Series.html",
    "title": "7  Series temporales",
    "section": "",
    "text": "7.1 Importación de las librerías y Dataset\nPrimero, antes de comenzar con el análisis de series temporales, importaremos todas las librerías necesarias para aplicar los diferentes datos, además de importar el Dataset train.csv.\nlibrary(tidyverse)  \n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)  \nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nlibrary(TTR)\n\nWarning: package 'TTR' was built under R version 4.3.3\n\nlibrary(forecast)\n\nWarning: package 'forecast' was built under R version 4.3.3\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\ntrain &lt;- read_csv(\"train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nComo ya tenemos todo bien importado, comenzamos.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Series temporales</span>"
    ]
  },
  {
    "objectID": "Series.html#análisis-de-los-datos",
    "href": "Series.html#análisis-de-los-datos",
    "title": "7  Series temporales",
    "section": "7.2 Análisis de los datos",
    "text": "7.2 Análisis de los datos\nAntes de comenzar con lo principal, vamos a analizar si el dataset es apto para poder sacar alguna información importante sobre las series temporales.\nNormalmente, los datasets válidos para series temporales son de la clase ts o tienen en sus datos alguna variable relacionado con el tiempo.\nSin embargo, al ser nuestro dataset sobre cuentas de instagram, no presenta ninguna de estas características. Además vamos a intentar utilizar el método time, a ver si conseguimos algo de información.\n\n#time(train)\n#Error in attr(x, \"tsp\") &lt;- c(1, NROW(x), 1) : \n#parámetros no válidos para series temporales\n\nComo podemos observar, este dataset no es válido para series temporales.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Series temporales</span>"
    ]
  },
  {
    "objectID": "Series.html#componentes-de-series-temporales",
    "href": "Series.html#componentes-de-series-temporales",
    "title": "7  Series temporales",
    "section": "7.3 Componentes de Series Temporales",
    "text": "7.3 Componentes de Series Temporales\nAunque no sea válido, vamos a ver si conseguimos sacar algo de información con los componentes que nos facilitan el análisis de series temporales.\n\n#ggseasonplot(train, col = rainbow(12), year.labels = TRUE)\n#Error in ggseasonplot(train, col = rainbow(12), year.labels = TRUE) : \n#autoplot.seasonplot requires a ts object, use x=object\n\nclass(train)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nComo podemos ver, al ser no ser un objeto de serie temporal, no es posible hacer nada con las librerias forecast y TTR.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Series temporales</span>"
    ]
  },
  {
    "objectID": "Series.html#conversión-a-un-objeto-de-serie-temporal",
    "href": "Series.html#conversión-a-un-objeto-de-serie-temporal",
    "title": "7  Series temporales",
    "section": "7.4 Conversión a un objeto de serie temporal",
    "text": "7.4 Conversión a un objeto de serie temporal\nComo de base no podemos realizar ninguna operación y no podemos sacar ninguna información al respecto, vamos a intentar convertir nuestro dataset en uno apto para hacerlo.\nPara ello podríamos convertir alguna columna de nuestro dataset en un serie temporal, pero no tenemos ni índices de tiempo ni tenemos ninguna información adicional que nos indique cada cuanto tiempo se ha analizado la cuenta.\nPor lo tanto, voy a asumir que la columna description_lenght puede ser tratada como el índice del tiempo. En este caso convertiremos la columna #follows en una serie temporal.\n\ntrain_desc &lt;- train[order(train$`description length`),]\n\nnum_follows_ts &lt;- ts(train_desc$`#follows`, frequency=1)\n\nplot(num_follows_ts, ylab = \"num_follows\", xlab = \"description_length\", main = \"Series Temporal de num_follows vs description_length\")\n\n\n\n\n\n\n\n\nYa tenemos una serie temporal, aunque sabemos que no tiene sentido, por lo que toda información que tomemos va a ser inválidas ya que nos estamos basando únicamente en suposiciones.\n\n#ggseasonplot(num_follows_ts, col = rainbow(length(unique(train$`description length`))), year.labels = TRUE)\n#Error in ggseasonplot(num_follows_ts, col = rainbow(length(unique(train$`description length`))),  : \n#Data are not seasonal\n\nAquí hay un ejemplo, al no haber un índice de tiempo real, no podemos hacer el análisis de las estaciones, ya que los datos no están sacados para este fin.\n\nlibrary(ggplot2)\n#ggsubseriesplot(num_follows_ts) +\n#  ylab(\"N. Follows\") +\n#  ggtitle(\"Seasonal subseries plot: num_follows_ts\")\n#Error in ggsubseriesplot(num_follows_ts) : Data are not seasonal",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Series temporales</span>"
    ]
  },
  {
    "objectID": "Series.html#métodos-de-pronóstico",
    "href": "Series.html#métodos-de-pronóstico",
    "title": "7  Series temporales",
    "section": "7.5 Métodos de pronóstico",
    "text": "7.5 Métodos de pronóstico\nVamos a intentar probar a realizar algún pronóstico, a ver si podemos sacar algo.\n\nh &lt;- 10\nmdata.num_follows &lt;- naive(num_follows_ts, h)\nplot(mdata.num_follows)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Series temporales</span>"
    ]
  },
  {
    "objectID": "Series.html#conclusión",
    "href": "Series.html#conclusión",
    "title": "7  Series temporales",
    "section": "7.6 Conclusión",
    "text": "7.6 Conclusión\nHe llegado a la conclusión de que con este conjunto de datos no es posible hacer un análisis de series temporales ya que toda información que saquemos, al no haber índices de tiempo ni variables que nos indiquen cuando ha ocurrido, será muy dispar y difícil de analizar.\nAdemás, si asumimos una variable cualquiera como índice de tiempo, al ser los datos o 1 o 0 o datos muy dispares, nos darán como resultado gráficas muy difíciles de interpretar y al no estar hecho para series temporales, las estaciones no están muy bien definidas.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Series temporales</span>"
    ]
  },
  {
    "objectID": "Otras_técnicas.html",
    "href": "Otras_técnicas.html",
    "title": "8  Otras técnicas",
    "section": "",
    "text": "8.1 Análisis de Redes Sociales\nSe trata de una disciplina con base sólida de Matemática aplicada, usando Teoría de Grafos y Matemática Discreta.\nSu principal objetivo es descubrir las relaciones entre los elementos de una red y extraer conocimiento acerca de las estructuras sociales que existen en esa red.\nSin embargo, los datos que disponemos no nos permiten realizar esta técnica, ya que no tenemos ningún dato que nos indique la relación entre varias cuentas, por lo que nos es imposible aplicar teoría de grafos.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Otras técnicas</span>"
    ]
  },
  {
    "objectID": "Otras_técnicas.html#algebra-lineal",
    "href": "Otras_técnicas.html#algebra-lineal",
    "title": "8  Otras técnicas",
    "section": "8.2 Algebra Lineal",
    "text": "8.2 Algebra Lineal\nEl álgebra lineal proporciona herramientas para representar y operar con conjuntos de datos, como matrices y vectores, de manera eficiente.\nSin embargo, nosotros no disponemos de matrices ni vectores, además no tiene sentido crearlas ya que cambiaría por completo el objetivo de este artículo, que es estudiar cuando una cuenta de instagram es falsa o no. Esto significa que no tiene sentido aplicar esta técnica a nuestro dataset.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Otras técnicas</span>"
    ]
  }
]